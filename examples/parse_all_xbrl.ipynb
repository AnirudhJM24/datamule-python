{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIK0000759828.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 11/7975 [00:02<33:35,  3.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 66\u001b[0m\n\u001b[0;32m     62\u001b[0m         process_company_concept_file(file_path, output_dir)\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m tqdm(json_files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing files\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     61\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(company_concepts_dir, filename)\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mprocess_company_concept_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m, in \u001b[0;36mprocess_company_concept_file\u001b[1;34m(file_path, output_dir)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     32\u001b[0m     table_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcik_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcsvfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Assume all dictionaries in the list have the same keys\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfieldnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: might setup faster parsers or use multiprocessing to speed up the process\n",
    "import datamule as dm\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_company_concept_file(file_path, output_dir):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            company_concepts = json.load(f)\n",
    "\n",
    "        parsed_data = dm.parse_company_concepts(company_concepts)\n",
    "\n",
    "        cik = os.path.basename(file_path).replace('CIK', '').replace('.json', '').lstrip('0')\n",
    "        cik_dir = os.path.join(output_dir, cik)\n",
    "        os.makedirs(cik_dir, exist_ok=True)\n",
    "\n",
    "        # Write metadata.csv\n",
    "        with open(os.path.join(cik_dir, 'metadata.csv'), 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=['cik', 'category', 'fact', 'label', 'description', 'unit'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows({k: v for k, v in item.items() if k != 'table'} for item in parsed_data)\n",
    "\n",
    "        # Write table CSVs and create locations.csv\n",
    "        locations = []\n",
    "        for index, item in enumerate(parsed_data, start=1):\n",
    "            if item['table']:\n",
    "                table_file = f\"{index:04d}.csv\"\n",
    "                with open(os.path.join(cik_dir, table_file), 'w', newline='') as csvfile:\n",
    "                    if item['table']:\n",
    "                        # Assume all dictionaries in the list have the same keys\n",
    "                        fieldnames = item['table'][0].keys()\n",
    "                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                        writer.writeheader()  # Write the header row\n",
    "                        writer.writerows(item['table'])  # Write the data rows\n",
    "\n",
    "                locations.append({'file': table_file, 'label': item['fact']})\n",
    "\n",
    "        # Write crosswalk.csv\n",
    "        with open(os.path.join(cik_dir, 'crosswalk.csv'), 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=['file', 'label'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(locations)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    start_time = time()\n",
    "\n",
    "    company_concepts_dir = 'company_concepts'\n",
    "    output_dir = 'company_concept_csv'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    json_files = [f for f in os.listdir(company_concepts_dir) if f.endswith('.json')]\n",
    "    print(json_files[803])\n",
    "\n",
    "    for filename in tqdm(json_files, desc=\"Processing files\"):\n",
    "        file_path = os.path.join(company_concepts_dir, filename)\n",
    "        process_company_concept_file(file_path, output_dir)\n",
    "\n",
    "    print(f\"Processing completed in {time() - start_time:.2f} seconds\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
